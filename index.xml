<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>uks&#39;s blog</title>
    <link>http://ukeeysdis.github.io/</link>
    <description>Recent content on uks&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>ukeeysdis</copyright>
    <lastBuildDate>Sun, 03 Jan 2021 21:02:16 +0800</lastBuildDate>
    
        <atom:link href="http://ukeeysdis.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于</title>
      <link>http://ukeeysdis.github.io/about/</link>
      <pubDate>Wed, 01 Jan 2020 21:38:52 +0800</pubDate>
      
      <guid>http://ukeeysdis.github.io/about/</guid>
      
        <description>&lt;h3 id=&#34;个人简介&#34;&gt;个人简介&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;2019年计算机科学与技术专业本科毕业，在百度核心搜索部实习后，校招入职腾讯微信，从事C++后台开发。&lt;/p&gt;
&lt;h3 id=&#34;工作经历&#34;&gt;工作经历&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;2018.5-2018.8 百度核心搜索部，实习3个月，从事百度搜索推荐架构相关后台工作&lt;/li&gt;
&lt;li&gt;2019.11-2019.03 腾讯微信，实习生&lt;/li&gt;
&lt;li&gt;2019.06-至今 腾讯微信，正式入职&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>定位一次线上CPU的毛刺问题</title>
      <link>http://ukeeysdis.github.io/post/troubleshoot_a_sudden_cpu_spike/</link>
      <pubDate>Sun, 03 Jan 2021 21:02:16 +0800</pubDate>
      
      <guid>http://ukeeysdis.github.io/post/troubleshoot_a_sudden_cpu_spike/</guid>
      
        <description>&lt;p&gt;这篇文章记录一次线上cpu毛刺的定位排查过程，希望能帮助到有需要的同学，同时也做一个复盘，下次再遇见类似情况可以花更少时间解决。
cpu毛刺是指在短时间内，cpu的使用率飙升，但很快又降到正常水平，由于毛刺可能是偶发的，不是一直存在，甚至无法复现，所以定位起来比较困难，需要借助一些工具进行协助定位。&lt;/p&gt;
&lt;h3 id=&#34;发现问题&#34;&gt;发现问题&lt;/h3&gt;
&lt;p&gt;最近突然收到个别模块的一些失败的告警（由于告警实在太多，也没有怎么注意），后来告警触发了运维拉群才注意原来这个模块的失败是因为存在cpu毛刺，短时间无法处理其他请求导致的，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../image/cpu_spike.png&#34; alt=&#34;cpu_spike&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;定位问题&#34;&gt;定位问题&lt;/h3&gt;
&lt;h4 id=&#34;难点&#34;&gt;难点&lt;/h4&gt;
&lt;p&gt;定位cpu问题一般可以使用&lt;code&gt;top&lt;/code&gt;以及&lt;code&gt;perf&lt;/code&gt;等命令协助定位，但由于毛刺出现的时间较短，如果用perf命令是采集一段时间的cpu使用，那段时间不一定会出现毛刺，并且就算出现了毛刺，也无法判断出消耗cpu较高的调用是不是导致毛刺的操作。&lt;/p&gt;
&lt;h4 id=&#34;思路&#34;&gt;思路&lt;/h4&gt;
&lt;p&gt;一般来说，出现毛刺有几个原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;请求突涨，正常的cpu上涨，这个可以通过监控/日志发现；&lt;/li&gt;
&lt;li&gt;部分请求的参数导致，比如需要处理的信息过多，导致长尾case；&lt;/li&gt;
&lt;li&gt;后台有定时运行的任务，抢占了cpu&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们可以通过脚本去监控服务的cpu占用情况，如果检测到服务cpu占用超过阈值，那就执行相关命令记录一些必要的信息，保存下来进行分析。
常用的命令有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;top：查看系统/进程的cpu、内存等信息&lt;/li&gt;
&lt;li&gt;perf：以函数纬度统计进程的cpu使用情况，可以记录一段时间内的情况，并且生成相关文件，可用于生成火焰图，排查性能瓶颈必备利器&lt;/li&gt;
&lt;li&gt;strace：跟踪进程的系统调用，配合-c选项可以统计进程某段时间的系统调用次数等信息&lt;/li&gt;
&lt;li&gt;pstack/gstack：记录进程当前的调用栈&lt;/li&gt;
&lt;li&gt;gcore：主动生成进程当前的coredump&lt;/li&gt;
&lt;li&gt;pidstat：查看进程占用的各种资源的信息，可以用来看进程上下文切换次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于原因1，如果请求涨的比较少，但cpu却狂飙，可能是服务的进程/线程数开的过多，彼此间切换的开销加大，可以使用&lt;code&gt;pstree -p pid&lt;/code&gt;查看子线程/进程个数，并且使用&lt;code&gt;pidstat&lt;/code&gt;命令查看非自愿上下文切换次数（系统强制调度），如果非自愿上下文切换次数跟平时比差异较大，说明线程/进程数开太多&lt;/p&gt;
&lt;p&gt;对于原因2，可以借助日志，把每个请求的耗时打印出来，找到耗时较高的请求，进行具体分析，不过由于毛刺出现期间cpu并不空闲，所以会导致期间的请求耗时都比较高，所以需要根据出现毛刺的时间，以及请求进入的时间等信息协助定位&lt;/p&gt;
&lt;p&gt;对于原因3，可以根据perf命令进行定位，查看是什么操作占用过多cpu，或者使用&lt;code&gt;pstack&lt;/code&gt;命令把当前调用栈打印出来&lt;/p&gt;
&lt;p&gt;这样的思路可能只适用于使用cgroup等进行资源隔离的服务，毕竟如果资源没有隔离，那可能整台机器都处于高负载，使用命令也会得不大及时的处理，影响结果的判断。&lt;/p&gt;
&lt;p&gt;参考脚本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# svr pid which perf record&lt;/span&gt;
svr_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# perf job pid&lt;/span&gt;
perf_job_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# strace job pid&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# strace_job_pid=0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; :
&lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# get svr pid&lt;/span&gt;
    cur_svr_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;ps -ef | grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;svr_name&amp;#34;&lt;/span&gt; | grep -v grep | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
    echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INFO: cur svr pid:&amp;#34;&lt;/span&gt;$cur_svr_pid
    &lt;span style=&#34;color:#75715e&#34;&gt;# get svr cpu&lt;/span&gt;
    cur_cpu&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;top -p $cur_svr_pid -n &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{if (NR == 8) print $10}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
    echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INFO: cur cpu:&amp;#34;&lt;/span&gt;$cur_cpu
    &lt;span style=&#34;color:#75715e&#34;&gt;# cpu &amp;gt; core*100*80% and svr pid is valid&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# because, svr maybe restart&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$cur_cpu&lt;span style=&#34;color:#e6db74&#34;&gt; &amp;gt; 480.0&amp;#34;&lt;/span&gt; | bc&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt; -eq &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; $svr_pid -eq &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; -o $svr_pid -eq $cur_svr_pid &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
				&lt;span style=&#34;color:#75715e&#34;&gt;# perf... not run&lt;/span&gt;
				&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; $perf_job_pid -eq &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
				&lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
				&lt;span style=&#34;color:#75715e&#34;&gt;# run a job&lt;/span&gt;
    		perf record -p $cur_svr_pid -o perf.txt.&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$cur_cpu&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &amp;amp;
				&lt;span style=&#34;color:#75715e&#34;&gt;#strace -fTtc -p $cur_svr_pid -o strace.txt.&amp;#34;$cur_cpu&amp;#34; &amp;amp;&lt;/span&gt;
				&lt;span style=&#34;color:#75715e&#34;&gt;#pstack $cur_svr_pid &amp;gt; pstack.txt.&amp;#34;$cur_cpu&amp;#34; &amp;amp;&lt;/span&gt;
				&lt;span style=&#34;color:#75715e&#34;&gt;#gcore $cur_svr_pid;mv core.$cur_svr_pid core.&amp;#34;$cur_svr_pid.&amp;#34;&amp;#34;$cur_cpu&amp;#34; &amp;amp;&lt;/span&gt;
   		 	svr_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$cur_svr_pid
    		perf_job_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;jobs -l | grep perf.txt. | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
				&lt;span style=&#34;color:#75715e&#34;&gt;#strace_job_pid=`jobs -l | grep strace.txt. | awk &amp;#39;{print $2}&amp;#39;`&lt;/span&gt;
    		echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;BEGIN: perf job pid:&amp;#34;&lt;/span&gt;$perf_job_pid
    		&lt;span style=&#34;color:#75715e&#34;&gt;#echo &amp;#34;BEGIN: strace job pid:&amp;#34;$strace_job_pid&lt;/span&gt;
    		echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;BEGIN: begin time:&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;date +%s&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
		&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;
				&lt;span style=&#34;color:#75715e&#34;&gt;# maybe cpu &amp;lt; 80% or svr is restart&lt;/span&gt;
	  		&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; $perf_job_pid -ne &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
	 			&lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
      			kill -2 $perf_job_pid
      			&lt;span style=&#34;color:#75715e&#34;&gt;#kill -2 $strace_job_pid&lt;/span&gt;
		  			echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;END: end job.end time:&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;date +%s&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
		  			echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;END: perf job pid:&amp;#34;&lt;/span&gt;$perf_job_pid
		  			&lt;span style=&#34;color:#75715e&#34;&gt;#echo &amp;#34;END: strace job pid:&amp;#34;$strace_job_pid&lt;/span&gt;
		  			echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;END: svr_pid:&amp;#34;&lt;/span&gt;$svr_pid&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; cur_svr_pid:&amp;#34;&lt;/span&gt;$cur_svr_pid
		  			&lt;span style=&#34;color:#75715e&#34;&gt;# clear pid&lt;/span&gt;
		  			svr_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
		  			perf_job_pid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
		  			&lt;span style=&#34;color:#75715e&#34;&gt;#strace_job_pid=0&lt;/span&gt;
    		&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
  	&lt;span style=&#34;color:#66d9ef&#34;&gt;fi&lt;/span&gt;
 		&lt;span style=&#34;color:#75715e&#34;&gt;# sleep top default flush time&lt;/span&gt;
    sleep &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个脚本的功能就是使用&lt;code&gt;top -p pid&lt;/code&gt;命令定时查看服务的cpu负载，高于80%（脚本中是6核机器，所以是480，需要自行更改）就开始使用perf等命令采集信息，由于top命令默认是3s更新一次信息，所以脚本会sleep 3s重新检查cpu，如果低于阈值，就干掉相关的采集命令，进行下一轮采集。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;这个有毛刺的模块，一开始使用脚本发现cpu是消耗在&lt;code&gt;unordered_map&lt;/code&gt;的查找操作中，但平时运行时根据perf命令的结果显示也是&lt;code&gt;unordered_map&lt;/code&gt;的查找操作消耗cpu比较多，所以怀疑极大可能是因为上面所说的原因2导致。通过日志发现确实有超长耗时的请求，捞出来看了下是因为请求的query长度过长，分词后需要匹配的词典过多导致cpu消耗太大。&lt;/p&gt;
&lt;p&gt;因此后续考虑加入布隆过滤器提前过滤掉不可能命中的query，减少去匹配的次数，从而降低cpu利用率。&lt;/p&gt;
&lt;p&gt;其实排查这种问题，还是要对服务有一定的熟悉度，平时就能大概知道服务会有哪些问题，也不至于出现问题就像无头苍蝇一样。并且有了一定的调试经验后，往往通过一些简单的命令和日志就可以发现问题。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>2020总结</title>
      <link>http://ukeeysdis.github.io/post/2020_summary/</link>
      <pubDate>Sun, 03 Jan 2021 15:51:15 +0800</pubDate>
      
      <guid>http://ukeeysdis.github.io/post/2020_summary/</guid>
      
        <description>&lt;p&gt;已经很久没有写博客了，上一次应该18年9月对秋招结束的一个总结（因为工作之后太懒：）&lt;/p&gt;
&lt;p&gt;不管是在工作中还是平时收获的东西，还是应当像之前在学校一样花时间记录下来，不然很容易就忘记了，等下次再遇到，又得花时间重新收集资料，如此反复。&lt;/p&gt;
&lt;p&gt;这篇文章仅记录一下在此之前我的一些生活以及工作历程，就当是对之前的一个大总结了。&lt;/p&gt;
&lt;h3 id=&#34;实习&#34;&gt;实习&lt;/h3&gt;
&lt;p&gt;当时在北京实习完后，毕业前回到成都，在学校待着，迫于生计，又找了一个实习，是一家做大数据安全的小公司（现在已经被收购），工作内容和之前在百度实习的时候类似，是做流式计算相关的东西，带我的人让我去预研一个计算相关的组件（叫啥忘了），我只实习了一个月就走了，因为预研实在是难受，每天坐在那里看论文，完全没有融入感，加上实习工资也比较低。
这段经历让我明白两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;小公司可能因为用到开源组件更多一些，对新技术的接受程度其实更高，历史包袱没有那么重，比如他们已经开始使用Rust，并且尝试使用业界比较前沿的大数据计算组件&lt;/li&gt;
&lt;li&gt;早9晚6真的很舒服：）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;随后，我联系了校招的面试官，能否在成都腾讯提前实习一段时间，能够提前熟悉一下工作内容，并且恰好也在成都。&lt;/p&gt;
&lt;p&gt;在一番协商后，我在成都腾讯入职了。&lt;/p&gt;
&lt;p&gt;因为是实习的缘故，所以工作没有那么多，主要还是熟悉一些开发环境然后做一下不太重要的小需求。当时工作中也问了导师的不少问题，大多都跟工作环境相关的，不过说实话他不是很友好。后来因为做的工作内容和心理预期不太符合，再加上待着比较难受，就联系了另外的团队，简单聊了一下，最后更换了入职的组。（及时止损很重要，其实觉得挺对不起原leader，他人挺好&lt;/p&gt;
&lt;h3 id=&#34;正式入职&#34;&gt;正式入职&lt;/h3&gt;
&lt;p&gt;毕业后，我在广州腾讯正式入职了，女朋友也找到了实习，不过是在深圳腾讯，所以我每周五得坐最后一趟班车去深圳，然后周一再坐最早的班车回广州。
工作上面因为之前实习了一段时间，以及毕业设计是跟libco协程相关的，所以对环境有了一定的熟悉度，入职的前两周应导师的安排，阅读了微信用的rpc框架源码（因为随后工作中会大量使用），并且总结成了pdf发到组里（这一点是导师要求的，因为这也是个人输出的一部分，他的原话大意是花了时间，一定要让老大看到你做了什么，有产出才行）。他也给我安排了随后的一些学习计划，不过是在工作中进行，比如阅读phxpaxos以及phxqueue的源码，业务和组件两条腿走路。（不过即使到现在，这两个组件的源码我还是没有开始染指，囧）&lt;/p&gt;
&lt;p&gt;微信后台有不少沉淀的优秀资料与组件以及架构，在这过程中：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在分布式方面，我熟悉了分布式相关的原理以及一些常见的分布式算法，比如事务相关的，常见的2PC、3PC、消息表、TCC以及事务消息，副本的一致性，Quorum算法，阅读了raft和paxos的论文，raft其实之前在毕业之前就做过6.824的课程，但忘的太厉害。paxos目前在微信后台大量使用，特别是存储，基于phxpaxos实现了强一致的kv，是微信的基石。选主需要用的租约机制，数据路由需要用到的一致性hash等算法。&lt;/p&gt;
&lt;p&gt;这里比较推荐刘杰的《分布式系统原理介绍》这个PDF以及《数据密集型应用系统设计》这本书。了解这些原理固然需要时间，但运用这些算法去完成一个能解决实际问题的项目，这才是最难的。我们如果没有实际的项目，其实很难完全掌握这些算法，不过也可以退而求次，有机会的话去阅读一些源码，比如paxos，它的原理以及证明在掌握了之后，真实用在工程中，会存在性能问题，phxpaxos就是在针对basic paxos优化之后的产物。&lt;/p&gt;
&lt;p&gt;RPC方面就主要是微信自研的，整体是一个mutli-reactors，其中大量使用了libco协程，libco是把网络相关的系统调用进行了hook实现的协程，rpc的请求路由一般采用一致性hash实现，这样可以让同一个用户的请求尽量到同一台机器，便于业务做缓存以及查问题等。名字服务是少有的使用第三方开源组件实现的，用了zookeeper，这个东西我还不太了解。&lt;/p&gt;
&lt;p&gt;在这方面，我还需要多加努力，很多东西都是一知半解。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在业务架构方面，我主要熟悉了微信消息系统、群、关系链、朋友圈、互通系统的架构设计，其中使用到的分布式seq算法和各种容灾策略，以及微信的多idc架构，这些让我受益匪浅，因为这样的机会很难得，这是一套能支撑起十亿人使用的业务架构，放在全球也是很少的。不过其实已经很成熟了，对于新人来说，有一个很大的缺点是熟悉了业务之后，会明显感受到成长缓慢，因为平时的工作内容大多还是在原来的基础上做需求，它的业务性质就已经决定了，可用性高于一切，不管是项目或者发布，都得为了可用性考虑，所以架构上基本不可能再改变。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其他的便是一些比较琐碎的了，比如编码规范，主要阅读了googleC++的编码规范，以及一些文档，比如protobuf的官方文档，语言方面主要读了《Effective modern C++》。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里的总结其实应该算是从正式入职截止到去年8月份一年多，因为女朋友实习完后也没有在广州找到合适的，最后还是去了深圳，每周来回跑长期下去也不是一个办法，再加上一些其他原因，我选择了活水到深圳。这段经历对我来说收获颇丰，开阔了我的眼界，也学习到了不少东西，也需要花不少时间去消化总结；认识到的同事也都很好，昨年上半年还拿了不错的绩效，其实还真的不太舍得。&lt;/p&gt;
&lt;p&gt;随后到了深圳，终于不用每周末再来回奔波了，不过房价真的比广州贵太多。也就是昨年下半年。&lt;/p&gt;
&lt;p&gt;主要学习到的是搜索相关的后台架构，以前对搜索引擎的工作机制不太了解，现在算是有了一个大致的轮廓了。对于工程来说，有几点是可以发力的，分布式爬虫（不过我们这边不算通用搜索，没有爬虫），在线召回（主要是求交算法的优化），离线索引（索引的管理与压缩），我的工作内容偏业务一点，主要是引擎的使用方，不过也需要去掌握引擎的原理。搜索系统对性能比较敏感，对耗时的要求很高，就算是业务方，也需要做不少优化工作。并且相比于普通业务来说，搜索业务相对复杂，一些工具的使用也更多一些，比如查性能瓶颈以及内存泄漏和越界等，这些让我在定位和调优工具的使用上有所提升。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;以上是我对过去学到的东西以及过程的一些总结，里面没有什么太多实质性的内容，更多的是梳理。整体来说不算特别满意，主要是少了总结，比较零散，导致很多遗忘，这一点非常不好，后续我会做一些具体的整理。&lt;/p&gt;
&lt;p&gt;之前读过一篇文章，里面提到技术人员的一些原则，其中有一点是“由始而终”，即先想清楚目标，再努力实现，学习也是一样，要带着目标去针对性学习，而不是零零散散东看一篇文章，西看一篇文章，知识要成体系，相辅相成，这很重要。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
